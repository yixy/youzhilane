

## 计算机的性能设计 ##

从计算机组织和体系结构的角度来看，发人深省的是：一方面组成今日计算机奇迹的基本模块和50年前的计算机基本相同（冯诺依曼机）；另一方面，从现有材料中挤出最后一丁点性能的技术都变得日益复杂。

下面简单介绍计算机设计所涉及的关键因素。

* CPU的速度：当芯片制造商忙于研究怎样不断提高芯片集成度的同时，处理器的设计者必须提供更加复杂的技术来填饱这个怪物。

转移预测（branch prediction）：流水线技术并不是百分之百完美的解决方案。实际上，有很多潜在的因素会使得流水线不能达到最佳效率。一个典型的情况是，如果遇到一条转移指令，则后面那些已经进入流水线的指令就都无效了。换句话说，我们必须清空（Flush）流水线，从要转移的目标位置处重新取指令放入流水线。这个现实的问题在于处理器一遇到分支指令，整个指令流水线就被打乱一次，稍后才能恢复到正常。显然，这影响了机器的运行速度。为了解决这个问题，处理器通过提前考察取自内存的指令代码并预测哪条分支指令或哪组指令将会被执行。分支预测的核心问题是，转移是发生还是不发生。换句话说，条件转移的条件会不会成立。这当然是很困难的，几乎不可能。想想看，如果能提前知道结果，还执行这些指令干嘛。但是，从统计学的角度来看，有些事情一旦出现，下一次还会出现的概率较大。一个典型例子就是循环。

数据流分析（data flow analysis）：处理器通过分析哪一条指令依赖其他的结果或数据，来优化指令调度。这种乱序执行的做法，在事实上，准备好的指令就可以执行，不必按照原来程序的顺序执行，这样减少了不必要的延时。

推测执行（speculative execution）：使用转移预测和数据流分析，一些处理器让指令在程序实际执行前就“推测执行”，并把结果暂存起来。通过执行可能需要的指令，使处理器的执行机制尽可能地保持繁忙。

* 性能平衡：当处理器的性能以惊人的速度向前发展的时候，计算机的其他关键部件并没有跟上。这引发了寻求性能平衡的需求：调整组织和结构，以补偿各种部件之间的能力不匹配。

处理器和主存的接口问题是这些不匹配问题中最重要的。通过使DRAM接口更宽，增大数据总线的宽度。在DRAM芯片中加入高速缓存或其他缓冲机制。在主存和处理器之间引入更复杂和有效的高速缓存结构，减少主存访问频度。通过使用高速总线和分层总线来缓冲并使数据流结构化，从而增加处理器与主存之间相互连接的带宽。

另一个设计焦点是I/O设备的处理。解决方法包括缓冲和缓存机制，以及使用高速互连总线和更为精巧的总线结构。

* 芯片组织和体系结构的改进

1）提高处理器硬件速度。这个提速基本上要归功于处理器芯片上逻辑门尺寸减少，门电路更紧密集成在一起，信号传播时间显著降低，从而允许处理器提速，并且随着时钟速率提升，每个操作更迅速。

2）提高插入在处理器和主存之间Cache的容量和速度。

3）改变处理器的组织和体系结构以提高指令执行的有效速度。处理器指令执行逻辑变得越来越复杂，以允许处理器内指令并行执行。比如流水化和超标量化。本质上讲，超标量办法是允许单一处理器内有多条指令流失，这样，彼此无关的指令能够并行执行。

4）多核：是随着密度更高、时钟速率更高，带来了更高的消耗功率，同时由于RC延时等因素存在，这种方式已经达到某些基础性的物理限制。而后两种策略（2和3）的回报也到达了最小点。当代处理器的内部组织已是极其复杂并能榨出指令流最大份额的并行性。基于这些原因，设计者开始转向一种根本性的新办法来改善性能，使用两个简单的处理器而不是一个更复杂的处理器。在同一芯片上安排多个处理器并带有大的共享Cache，即多核。这样，若软件能有效地支持多核处理器的使用，则处理器数目的加倍几乎使性能加倍。

（分布式系统）

