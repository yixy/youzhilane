
## 1. 磁盘接口 ##

磁盘可以通过高速互连通道（磁盘接口）连接到计算机系统。

* IDE接口：integrated drive electronics，早期IBM PC机中使用的集成驱动电路。
* ATA接口：AT attachment，比IDE更快的接口，也称为PATA或并行ATA，以与SATA区分。
* SATA接口：serial ATA，串行ATA，是ATA的新版本。
* SCSI接口：small-computer-system-interconnect，发音为scuzzy
* 光纤接口：大型机或服务器使用，价格昂贵
* USB接口/FireWire接口：外置磁盘系统通常使用的接口

磁盘可以直接连接到计算机主板上，也可以放置到远端并通过高速网络与磁盘控制器相连。前者主要指DAS方式，后者主要指SAN和NAS方式。

## 2. DAS ##

我们熟知的个人电脑一般采用DAS(Direct Attached Storage)方式进行存储，即将磁盘直连到了主板上。DAS已经存在很多年了，就算到今天也是很多服务器的理想选择。但是它也有许多缺点，其中最重要的就是扩展性太差。

## 3. SAN ##

SAN (Storage Attached Network)，即存储区域网络，服务器通过光纤(Fibre Channel)交换机连接存储阵列（一般采用SCSI、FC-AL接口），实现专用数据的存储私网。在SAN中，大量的磁盘通过高速网络与计算机服务器连接，通常磁盘采用RAID技术进行本地化组织，从而给服务器一个逻辑视图，使服务器看到的是一个很大且非常可靠的磁盘。尽管可能被网络分开，计算机和磁盘子系统仍然通过SCSI接口或光纤接口互相通信。SAN提供的是块设备的操作，文件系统只存在于各个服务器上。

## 4. NAS ##

NAS（Network-Attached Storage），即网络附加存储，服务器通过网络技术（TCP/IP、ATM、FDDI），采用业界标准文件共享协议，如NFS、HTTP、CIFS，实现通过网络存取数据。NAS提供的是文件的操作，NAS本身有自己的文件系统，服务器通过文件共享协议与NAS交互。

注意，NAS很像SAN，但是他通过使用网络文件系统协议如NFS或CIFS提供文件系统接口，而不是看似一个大磁盘的网络存储。

## 5. SAN与NAS的比较 ##

NAS和SAN最本质的区别就是文件系统：NAS有自已的文件系统。

* SAN结构中，文件系统分别位于各台服务器上，直接通过光纤交换机访问设备块。
* NAS结构中，则是每台服务器通过网络共享协议，与包含同一个文件系统NAS进行文件共享。

NAS以文件的形式+LAN连接存储介质；而SAN以块形式+光纤连接存储介质。

NAS架构的路径在虚拟目录层和文件系统层通信的时候，用以太网和TCP/IP协议代替了内存，这样做不但增加了大量的CPU指令周期（TCP/IP逻辑和以太网卡驱动程序），而且使用了低速传输介质（内存速度要比以太网快得多）。而SAN方式下，路径中比NAS方式多了一次FC访问过程，但是FC的逻辑大部分都由适配卡上的硬件完成，增加不了多少CPU的开销，而且FC访问的速度比以太网高，所以我们很容易得出结论，如果后端磁盘没有瓶颈，那么除非NAS使用快于内存的网络方式与主机通信，否则其速度永远无法超越SAN架构。但是如果后端磁盘有瓶颈，那么NAS用网络代替内存的方法产生的性能降低就可以忽略。比如，在大量随机小块I/O、缓存命中率极低的环境下，后端磁盘系统寻到瓶颈达到最大，此时前端的I/O指令都会处于等待状态，所以就算路径首段速度再快，也无济于事。此时，NAS系统不但不比SAN慢，而且由于其优化的并发I/O设计和基于文件访问而不是簇块访问的特性，反而可能比SAN性能高。

NAS对于大块顺序IO密集的环境，要比SAN慢一大截，原因是经过大量IO累积之后，总体差别就显出来了。不过，如果要用10G以太网，无疑要选用NAS，因为底层链路的速度毕竟是目前NAS的根本瓶颈。此外，如果是高并发随机小块I/O环境或者共享访问文件的环境，NAS会表现出很强的相对性能。如果SAN主机上的文件系统碎片比较多，那么读写某个文件时便会产生随机小块IO，而NAS自身文件系统会有很多优化设计，碎片相对较少。CPU密集型的应考虑使用NAS。
 
## 6. SAN与NAS整合 ##

NAS和SAN的整合也是存储设备的发展趋势。目前，很多高端NAS的后端存储实际上就采用了SAN。典型的场景可能是这样的，服务器再通过Ethernet Switch连到NAS上，NAS通过FC Switch连到SAN上，同时SAN也直接提供block级别的存储给服务器。
